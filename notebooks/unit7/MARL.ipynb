{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d3ead7",
   "metadata": {},
   "source": [
    "# Работаем с репозиторием ML-agents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93547fc",
   "metadata": {},
   "source": [
    "## Клонируем репу ml-agents для работы в среде unity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bb455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml-agents'...\n",
      "remote: Enumerating objects: 94896, done.\u001b[K\n",
      "remote: Counting objects: 100% (479/479), done.\u001b[K\n",
      "remote: Compressing objects: 100% (273/273), done.\u001b[K\n",
      "remote: Total 94896 (delta 277), reused 259 (delta 206), pack-reused 94417 (from 4)\u001b[K\n",
      "Receiving objects: 100% (94896/94896), 2.87 GiB | 9.54 MiB/s, done.\n",
      "Resolving deltas: 100% (69012/69012), done.\n",
      "Updating files: 100% (2333/2333), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Unity-Technologies/ml-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ff761",
   "metadata": {},
   "source": [
    "## Устанавливаем пакеты для ml-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878b8f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmin/HuggingFace/notebooks/unit7/ml-agents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmin/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///home/dmin/HuggingFace/notebooks/unit7/ml-agents/ml-agents-envs\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (3.1.1)\n",
      "Requirement already satisfied: grpcio<=1.53.2,>=1.11.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (1.48.2)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (11.3.0)\n",
      "Requirement already satisfied: protobuf<3.21,>=3.6 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml>=3.1.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: gym>=0.21.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (0.26.2)\n",
      "Requirement already satisfied: pettingzoo==1.15.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: numpy<1.24.0,>=1.23.5 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: filelock>=3.4.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/dmin/.local/lib/python3.10/site-packages (from grpcio<=1.53.2,>=1.11.0->mlagents_envs==1.2.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/dmin/.local/lib/python3.10/site-packages (from gym>=0.21.0->mlagents_envs==1.2.0.dev0) (0.1.0)\n",
      "Building wheels for collected packages: mlagents_envs\n",
      "  Building editable for mlagents_envs (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mlagents_envs: filename=mlagents_envs-1.2.0.dev0-0.editable-py3-none-any.whl size=3941 sha256=eaab7a1fc0f46adc8e7dce216aec6587924b7bcf05dc6c6462ad4a313e30980b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hrbrcuek/wheels/95/fe/76/9f03985af3a5ae8a45a3dacaa9aa5664987a3c4f70d99bdb9d\n",
      "Successfully built mlagents_envs\n",
      "Installing collected packages: mlagents_envs\n",
      "  Attempting uninstall: mlagents_envs\n",
      "    Found existing installation: mlagents_envs 1.2.0.dev0\n",
      "    Uninstalling mlagents_envs-1.2.0.dev0:\n",
      "      Successfully uninstalled mlagents_envs-1.2.0.dev0\n",
      "Successfully installed mlagents_envs-1.2.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///home/dmin/HuggingFace/notebooks/unit7/ml-agents/ml-agents\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: grpcio<=1.53.2,>=1.11.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.48.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (3.14.0)\n",
      "Requirement already satisfied: mlagents_envs==1.2.0.dev0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.2.0.dev0)\n",
      "Requirement already satisfied: numpy<1.24.0,>=1.23.5 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (11.3.0)\n",
      "Requirement already satisfied: protobuf<3.21,>=3.6 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml>=3.1.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.1.1 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (2.8.0)\n",
      "Requirement already satisfied: tensorboard>=2.14 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (2.20.0)\n",
      "Requirement already satisfied: six>=1.16 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: cattrs<1.7,>=1.1.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.5.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (25.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.14 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (0.34.4)\n",
      "Requirement already satisfied: onnx==1.15.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents==1.2.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: cloudpickle in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (3.1.1)\n",
      "Requirement already satisfied: gym>=0.21.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (0.26.2)\n",
      "Requirement already satisfied: pettingzoo==1.15.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: filelock>=3.4.0 in /home/dmin/.local/lib/python3.10/site-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/dmin/.local/lib/python3.10/site-packages (from gym>=0.21.0->mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (0.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (25.0)\n",
      "Requirement already satisfied: requests in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dmin/.local/lib/python3.10/site-packages (from huggingface_hub>=0.14->mlagents==1.2.0.dev0) (1.1.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/dmin/.local/lib/python3.10/site-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (2.3.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dmin/.local/lib/python3.10/site-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (3.8.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dmin/.local/lib/python3.10/site-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dmin/.local/lib/python3.10/site-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/dmin/.local/lib/python3.10/site-packages (from torch>=2.1.1->mlagents==1.2.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dmin/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.1.1->mlagents==1.2.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dmin/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.14->mlagents==1.2.0.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dmin/.local/lib/python3.10/site-packages (from requests->huggingface_hub>=0.14->mlagents==1.2.0.dev0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dmin/.local/lib/python3.10/site-packages (from requests->huggingface_hub>=0.14->mlagents==1.2.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dmin/.local/lib/python3.10/site-packages (from requests->huggingface_hub>=0.14->mlagents==1.2.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dmin/.local/lib/python3.10/site-packages (from requests->huggingface_hub>=0.14->mlagents==1.2.0.dev0) (2025.8.3)\n",
      "Building wheels for collected packages: mlagents\n",
      "  Building editable for mlagents (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mlagents: filename=mlagents-1.2.0.dev0-0.editable-py3-none-any.whl size=4109 sha256=401dee9ca9c1aed6e460d622a3b270d76a4b239e46f2c0978f2adcb1010acffd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x4_ismku/wheels/4e/40/5c/5b24813ac63c57708bbab0b7c9d8a21e42d72f8d4cae93f70c\n",
      "Successfully built mlagents\n",
      "Installing collected packages: mlagents\n",
      "  Attempting uninstall: mlagents\n",
      "    Found existing installation: mlagents 1.2.0.dev0\n",
      "    Uninstalling mlagents-1.2.0.dev0:\n",
      "      Successfully uninstalled mlagents-1.2.0.dev0\n",
      "Successfully installed mlagents-1.2.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# нужно перейти в папку ml-agents\n",
    "%cd ml-agents\n",
    "\n",
    "# Переходим в режим редактирования пакетов\n",
    "%pip install -e ml-agents-envs\n",
    "%pip install -e ml-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa5e65",
   "metadata": {},
   "source": [
    "# Обучение агента "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06f92a",
   "metadata": {},
   "source": [
    "## Запуск обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda632d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.2.0.dev0,\n",
      "  ml-agents-envs: 1.2.0.dev0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0+cu128\n",
      "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
      "[INFO] Connected new brain: SoccerTwos?team=1\n",
      "[INFO] Connected new brain: SoccerTwos?team=0\n",
      "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t2048\n",
      "\t  buffer_size:\t20480\n",
      "\t  learning_rate:\t0.0005\n",
      "\t  beta:\t0.005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t5\n",
      "\t  learning_rate_schedule:\tconstant\n",
      "\t  beta_schedule:\tconstant\n",
      "\t  epsilon_schedule:\tconstant\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t256\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t2000000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\t\n",
      "\t  save_steps:\t50000\n",
      "\t  team_change:\t200000\n",
      "\t  swap_steps:\t2000\n",
      "\t  window:\t10\n",
      "\t  play_against_latest_model_ratio:\t0.5\n",
      "\t  initial_elo:\t1200.0\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Resuming from results/SoccerTwos/SoccerTwos.\n",
      "[WARNING] Failed to load for module Policy. Initializing\n",
      "[WARNING] Failed to load for module Optimizer:critic. Initializing\n",
      "[INFO] Resuming training from step 0.\n",
      "/home/dmin/.local/lib/python3.10/site-packages/torch/utils/_device.py:103: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4421.)\n",
      "  return func(*args, **kwargs)\n",
      "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 30.550 s. Mean Reward: 0.000. Mean Group Reward: 0.032. Training. ELO: 1200.550.\n",
      "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 49.203 s. Mean Reward: 0.000. Mean Group Reward: -0.302. Training. ELO: 1200.987.\n",
      "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 74.930 s. Mean Reward: 0.000. Mean Group Reward: 0.022. Training. ELO: 1200.987.\n",
      "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 96.200 s. Mean Reward: 0.000. Mean Group Reward: 0.136. Training. ELO: 1200.987.\n",
      "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 122.814 s. Mean Reward: 0.000. Mean Group Reward: 0.125. Training. ELO: 1203.481.\n",
      "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 145.830 s. Mean Reward: 0.000. Mean Group Reward: -0.250. Training. ELO: 1203.148.\n",
      "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 171.352 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1202.135.\n",
      "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 188.374 s. Mean Reward: 0.000. Mean Group Reward: -0.077. Training. ELO: 1202.382.\n",
      "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 221.135 s. Mean Reward: 0.000. Mean Group Reward: -0.135. Training. ELO: 1200.264.\n",
      "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 234.624 s. Mean Reward: 0.000. Mean Group Reward: -0.015. Training. ELO: 1200.486.\n",
      "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 262.596 s. Mean Reward: 0.000. Mean Group Reward: 0.068. Training. ELO: 1201.667.\n",
      "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 277.713 s. Mean Reward: 0.000. Mean Group Reward: 0.151. Training. ELO: 1201.919.\n",
      "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 303.022 s. Mean Reward: 0.000. Mean Group Reward: 0.244. Training. ELO: 1202.289.\n",
      "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 327.578 s. Mean Reward: 0.000. Mean Group Reward: 0.088. Training. ELO: 1203.651.\n",
      "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 351.883 s. Mean Reward: 0.000. Mean Group Reward: 0.063. Training. ELO: 1204.721.\n",
      "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 377.535 s. Mean Reward: 0.000. Mean Group Reward: -0.139. Training. ELO: 1205.616.\n",
      "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 399.738 s. Mean Reward: 0.000. Mean Group Reward: 0.113. Training. ELO: 1206.607.\n",
      "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 433.139 s. Mean Reward: 0.000. Mean Group Reward: 0.093. Training. ELO: 1208.311.\n",
      "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 454.658 s. Mean Reward: 0.000. Mean Group Reward: 0.147. Training. ELO: 1210.581.\n",
      "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 489.042 s. Mean Reward: 0.000. Mean Group Reward: 0.143. Training. ELO: 1211.343.\n",
      "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 522.945 s. Mean Reward: 0.000. Mean Group Reward: -0.188. Training. ELO: 1211.223.\n",
      "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 546.449 s. Mean Reward: 0.000. Mean Group Reward: -0.222. Training. ELO: 1208.731.\n",
      "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 570.795 s. Mean Reward: 0.000. Mean Group Reward: -0.052. Training. ELO: 1211.272.\n",
      "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 609.524 s. Mean Reward: 0.000. Mean Group Reward: -0.329. Training. ELO: 1211.238.\n",
      "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 616.854 s. Mean Reward: 0.000. Mean Group Reward: 0.254. Training. ELO: 1211.991.\n",
      "[INFO] SoccerTwos. Step: 260000. Time Elapsed: 652.634 s. Mean Reward: 0.000. Mean Group Reward: -0.222. Training. ELO: 1210.777.\n",
      "[INFO] SoccerTwos. Step: 270000. Time Elapsed: 665.623 s. Mean Reward: 0.000. Mean Group Reward: 0.155. Training. ELO: 1212.227.\n",
      "[INFO] SoccerTwos. Step: 280000. Time Elapsed: 699.211 s. Mean Reward: 0.000. Mean Group Reward: 0.041. Training. ELO: 1213.824.\n",
      "[INFO] SoccerTwos. Step: 290000. Time Elapsed: 712.020 s. Mean Reward: 0.000. Mean Group Reward: -0.095. Training. ELO: 1213.562.\n",
      "[INFO] SoccerTwos. Step: 300000. Time Elapsed: 736.996 s. Mean Reward: 0.000. Mean Group Reward: -0.429. Training. ELO: 1212.107.\n",
      "[INFO] SoccerTwos. Step: 310000. Time Elapsed: 760.165 s. Mean Reward: 0.000. Mean Group Reward: 0.004. Training. ELO: 1211.943.\n",
      "[INFO] SoccerTwos. Step: 320000. Time Elapsed: 780.859 s. Mean Reward: 0.000. Mean Group Reward: -0.220. Training. ELO: 1211.582.\n",
      "[INFO] SoccerTwos. Step: 330000. Time Elapsed: 806.139 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1211.946.\n",
      "[INFO] SoccerTwos. Step: 340000. Time Elapsed: 829.682 s. Mean Reward: 0.000. Mean Group Reward: -0.154. Training. ELO: 1212.553.\n",
      "[INFO] SoccerTwos. Step: 350000. Time Elapsed: 856.457 s. Mean Reward: 0.000. Mean Group Reward: -0.178. Training. ELO: 1213.026.\n",
      "[INFO] SoccerTwos. Step: 360000. Time Elapsed: 876.335 s. Mean Reward: 0.000. Mean Group Reward: 0.198. Training. ELO: 1213.655.\n",
      "[INFO] SoccerTwos. Step: 370000. Time Elapsed: 903.277 s. Mean Reward: 0.000. Mean Group Reward: 0.150. Training. ELO: 1215.202.\n",
      "[INFO] SoccerTwos. Step: 380000. Time Elapsed: 915.891 s. Mean Reward: 0.000. Mean Group Reward: -0.007. Training. ELO: 1214.563.\n",
      "[INFO] SoccerTwos. Step: 390000. Time Elapsed: 941.877 s. Mean Reward: 0.000. Mean Group Reward: -0.195. Training. ELO: 1213.486.\n",
      "[INFO] SoccerTwos. Step: 400000. Time Elapsed: 964.510 s. Mean Reward: 0.000. Mean Group Reward: 0.037. Training. ELO: 1212.477.\n",
      "[INFO] SoccerTwos. Step: 410000. Time Elapsed: 998.996 s. Mean Reward: 0.000. Mean Group Reward: -0.148. Training. ELO: 1212.985.\n",
      "[INFO] SoccerTwos. Step: 420000. Time Elapsed: 1014.804 s. Mean Reward: 0.000. Mean Group Reward: 0.036. Training. ELO: 1214.306.\n",
      "[INFO] SoccerTwos. Step: 430000. Time Elapsed: 1040.562 s. Mean Reward: 0.000. Mean Group Reward: 0.094. Training. ELO: 1214.921.\n",
      "[INFO] SoccerTwos. Step: 440000. Time Elapsed: 1061.618 s. Mean Reward: 0.000. Mean Group Reward: -0.379. Training. ELO: 1217.189.\n",
      "[INFO] SoccerTwos. Step: 450000. Time Elapsed: 1077.118 s. Mean Reward: 0.000. Mean Group Reward: -0.054. Training. ELO: 1218.056.\n",
      "[INFO] SoccerTwos. Step: 460000. Time Elapsed: 1100.602 s. Mean Reward: 0.000. Mean Group Reward: 0.007. Training. ELO: 1219.082.\n",
      "[INFO] SoccerTwos. Step: 470000. Time Elapsed: 1115.367 s. Mean Reward: 0.000. Mean Group Reward: -0.170. Training. ELO: 1219.164.\n",
      "[INFO] SoccerTwos. Step: 480000. Time Elapsed: 1146.828 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1220.329.\n",
      "[INFO] SoccerTwos. Step: 490000. Time Elapsed: 1174.770 s. Mean Reward: 0.000. Mean Group Reward: 0.467. Training. ELO: 1221.835.\n",
      "[INFO] SoccerTwos. Step: 500000. Time Elapsed: 1188.422 s. Mean Reward: 0.000. Mean Group Reward: -0.406. Training. ELO: 1221.992.\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-499082.onnx\n",
      "[INFO] SoccerTwos. Step: 510000. Time Elapsed: 1212.636 s. Mean Reward: 0.000. Mean Group Reward: 0.278. Training. ELO: 1223.363.\n",
      "[INFO] SoccerTwos. Step: 520000. Time Elapsed: 1232.062 s. Mean Reward: 0.000. Mean Group Reward: -0.032. Training. ELO: 1228.232.\n",
      "[INFO] SoccerTwos. Step: 530000. Time Elapsed: 1253.214 s. Mean Reward: 0.000. Mean Group Reward: -0.157. Training. ELO: 1228.253.\n",
      "[INFO] SoccerTwos. Step: 540000. Time Elapsed: 1281.392 s. Mean Reward: 0.000. Mean Group Reward: 0.118. Training. ELO: 1229.996.\n",
      "[INFO] SoccerTwos. Step: 550000. Time Elapsed: 1300.586 s. Mean Reward: 0.000. Mean Group Reward: -0.065. Training. ELO: 1230.009.\n",
      "[INFO] SoccerTwos. Step: 560000. Time Elapsed: 1325.856 s. Mean Reward: 0.000. Mean Group Reward: -0.129. Training. ELO: 1231.313.\n",
      "[INFO] SoccerTwos. Step: 570000. Time Elapsed: 1347.069 s. Mean Reward: 0.000. Mean Group Reward: 0.494. Training. ELO: 1232.616.\n",
      "[INFO] SoccerTwos. Step: 580000. Time Elapsed: 1376.098 s. Mean Reward: 0.000. Mean Group Reward: 0.010. Training. ELO: 1232.379.\n",
      "[INFO] SoccerTwos. Step: 590000. Time Elapsed: 1387.473 s. Mean Reward: 0.000. Mean Group Reward: 0.031. Training. ELO: 1233.332.\n",
      "[INFO] SoccerTwos. Step: 600000. Time Elapsed: 1405.500 s. Mean Reward: 0.000. Mean Group Reward: 0.164. Training. ELO: 1234.003.\n",
      "[INFO] SoccerTwos. Step: 610000. Time Elapsed: 1447.167 s. Mean Reward: 0.000. Mean Group Reward: -0.009. Training. ELO: 1236.681.\n",
      "[INFO] SoccerTwos. Step: 620000. Time Elapsed: 1461.531 s. Mean Reward: 0.000. Mean Group Reward: 0.159. Training. ELO: 1237.944.\n",
      "[INFO] SoccerTwos. Step: 630000. Time Elapsed: 1492.066 s. Mean Reward: 0.000. Mean Group Reward: -0.260. Training. ELO: 1237.782.\n",
      "[INFO] SoccerTwos. Step: 640000. Time Elapsed: 1516.066 s. Mean Reward: 0.000. Mean Group Reward: 0.085. Training. ELO: 1237.671.\n",
      "[INFO] SoccerTwos. Step: 650000. Time Elapsed: 1534.606 s. Mean Reward: 0.000. Mean Group Reward: 0.181. Training. ELO: 1238.734.\n",
      "[INFO] SoccerTwos. Step: 660000. Time Elapsed: 1555.513 s. Mean Reward: 0.000. Mean Group Reward: 0.317. Training. ELO: 1239.678.\n",
      "[INFO] SoccerTwos. Step: 670000. Time Elapsed: 1585.316 s. Mean Reward: 0.000. Mean Group Reward: -0.003. Training. ELO: 1243.048.\n",
      "[INFO] SoccerTwos. Step: 680000. Time Elapsed: 1602.795 s. Mean Reward: 0.000. Mean Group Reward: 0.352. Training. ELO: 1242.304.\n",
      "[INFO] SoccerTwos. Step: 690000. Time Elapsed: 1641.636 s. Mean Reward: 0.000. Mean Group Reward: -0.014. Training. ELO: 1243.678.\n",
      "[INFO] SoccerTwos. Step: 700000. Time Elapsed: 1659.028 s. Mean Reward: 0.000. Mean Group Reward: 0.015. Training. ELO: 1246.113.\n",
      "[INFO] SoccerTwos. Step: 710000. Time Elapsed: 1696.376 s. Mean Reward: 0.000. Mean Group Reward: -0.132. Training. ELO: 1245.880.\n",
      "[INFO] SoccerTwos. Step: 720000. Time Elapsed: 1710.044 s. Mean Reward: 0.000. Mean Group Reward: 0.153. Training. ELO: 1247.203.\n",
      "[INFO] SoccerTwos. Step: 730000. Time Elapsed: 1736.776 s. Mean Reward: 0.000. Mean Group Reward: -0.108. Training. ELO: 1248.059.\n",
      "[INFO] SoccerTwos. Step: 740000. Time Elapsed: 1757.142 s. Mean Reward: 0.000. Mean Group Reward: -0.092. Training. ELO: 1247.451.\n",
      "[INFO] SoccerTwos. Step: 750000. Time Elapsed: 1774.505 s. Mean Reward: 0.000. Mean Group Reward: 0.347. Training. ELO: 1251.291.\n",
      "[INFO] SoccerTwos. Step: 760000. Time Elapsed: 1800.731 s. Mean Reward: 0.000. Mean Group Reward: -0.109. Training. ELO: 1254.073.\n",
      "[INFO] SoccerTwos. Step: 770000. Time Elapsed: 1824.851 s. Mean Reward: 0.000. Mean Group Reward: -0.428. Training. ELO: 1253.406.\n",
      "[INFO] SoccerTwos. Step: 780000. Time Elapsed: 1850.715 s. Mean Reward: 0.000. Mean Group Reward: -0.057. Training. ELO: 1251.650.\n",
      "[INFO] SoccerTwos. Step: 790000. Time Elapsed: 1874.630 s. Mean Reward: 0.000. Mean Group Reward: 0.036. Training. ELO: 1248.525.\n",
      "[INFO] SoccerTwos. Step: 800000. Time Elapsed: 1898.108 s. Mean Reward: 0.000. Mean Group Reward: -0.046. Training. ELO: 1251.315.\n",
      "[INFO] SoccerTwos. Step: 810000. Time Elapsed: 1924.118 s. Mean Reward: 0.000. Mean Group Reward: -0.062. Training. ELO: 1250.341.\n",
      "[INFO] SoccerTwos. Step: 820000. Time Elapsed: 1952.392 s. Mean Reward: 0.000. Mean Group Reward: 0.148. Training. ELO: 1253.509.\n",
      "[INFO] SoccerTwos. Step: 830000. Time Elapsed: 1979.990 s. Mean Reward: 0.000. Mean Group Reward: 0.098. Training. ELO: 1256.087.\n",
      "[INFO] SoccerTwos. Step: 840000. Time Elapsed: 2010.356 s. Mean Reward: 0.000. Mean Group Reward: -0.209. Training. ELO: 1254.821.\n",
      "[INFO] SoccerTwos. Step: 850000. Time Elapsed: 2027.797 s. Mean Reward: 0.000. Mean Group Reward: 0.253. Training. ELO: 1257.444.\n",
      "[INFO] SoccerTwos. Step: 860000. Time Elapsed: 2055.391 s. Mean Reward: 0.000. Mean Group Reward: 0.246. Training. ELO: 1263.945.\n",
      "[INFO] SoccerTwos. Step: 870000. Time Elapsed: 2074.639 s. Mean Reward: 0.000. Mean Group Reward: 0.462. Training. ELO: 1270.647.\n",
      "[INFO] SoccerTwos. Step: 880000. Time Elapsed: 2102.480 s. Mean Reward: 0.000. Mean Group Reward: 0.148. Training. ELO: 1275.324.\n",
      "[INFO] SoccerTwos. Step: 890000. Time Elapsed: 2125.174 s. Mean Reward: 0.000. Mean Group Reward: -0.336. Training. ELO: 1274.974.\n",
      "[INFO] SoccerTwos. Step: 900000. Time Elapsed: 2161.668 s. Mean Reward: 0.000. Mean Group Reward: -0.004. Training. ELO: 1275.334.\n",
      "[INFO] SoccerTwos. Step: 910000. Time Elapsed: 2176.593 s. Mean Reward: 0.000. Mean Group Reward: -0.139. Training. ELO: 1277.443.\n",
      "[INFO] SoccerTwos. Step: 920000. Time Elapsed: 2204.021 s. Mean Reward: 0.000. Mean Group Reward: -0.006. Training. ELO: 1277.485.\n",
      "[INFO] SoccerTwos. Step: 930000. Time Elapsed: 2222.472 s. Mean Reward: 0.000. Mean Group Reward: 0.024. Training. ELO: 1277.944.\n",
      "[INFO] SoccerTwos. Step: 940000. Time Elapsed: 2247.118 s. Mean Reward: 0.000. Mean Group Reward: 0.210. Training. ELO: 1279.925.\n",
      "[INFO] SoccerTwos. Step: 950000. Time Elapsed: 2280.379 s. Mean Reward: 0.000. Mean Group Reward: 0.553. Training. ELO: 1289.966.\n",
      "[INFO] SoccerTwos. Step: 960000. Time Elapsed: 2297.337 s. Mean Reward: 0.000. Mean Group Reward: -0.006. Training. ELO: 1298.404.\n",
      "[INFO] SoccerTwos. Step: 970000. Time Elapsed: 2332.259 s. Mean Reward: 0.000. Mean Group Reward: 0.049. Training. ELO: 1299.396.\n",
      "[INFO] SoccerTwos. Step: 980000. Time Elapsed: 2351.976 s. Mean Reward: 0.000. Mean Group Reward: -0.094. Training. ELO: 1299.216.\n",
      "[INFO] SoccerTwos. Step: 990000. Time Elapsed: 2379.257 s. Mean Reward: 0.000. Mean Group Reward: -0.043. Training. ELO: 1296.608.\n",
      "[INFO] SoccerTwos. Step: 1000000. Time Elapsed: 2399.409 s. Mean Reward: 0.000. Mean Group Reward: 0.044. Training. ELO: 1294.918.\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-999910.onnx\n",
      "[INFO] SoccerTwos. Step: 1010000. Time Elapsed: 2433.265 s. Mean Reward: 0.000. Mean Group Reward: 0.087. Training. ELO: 1295.408.\n",
      "[INFO] SoccerTwos. Step: 1020000. Time Elapsed: 2451.229 s. Mean Reward: 0.000. Mean Group Reward: 0.083. Training. ELO: 1299.279.\n",
      "[INFO] SoccerTwos. Step: 1030000. Time Elapsed: 2482.086 s. Mean Reward: 0.000. Mean Group Reward: 0.408. Training. ELO: 1301.006.\n",
      "[INFO] SoccerTwos. Step: 1040000. Time Elapsed: 2504.122 s. Mean Reward: 0.000. Mean Group Reward: 0.115. Training. ELO: 1308.636.\n",
      "[INFO] SoccerTwos. Step: 1050000. Time Elapsed: 2535.170 s. Mean Reward: 0.000. Mean Group Reward: 0.194. Training. ELO: 1313.608.\n",
      "[INFO] SoccerTwos. Step: 1060000. Time Elapsed: 2553.652 s. Mean Reward: 0.000. Mean Group Reward: 0.159. Training. ELO: 1315.196.\n",
      "[INFO] SoccerTwos. Step: 1070000. Time Elapsed: 2580.791 s. Mean Reward: 0.000. Mean Group Reward: -0.057. Training. ELO: 1316.954.\n",
      "[INFO] SoccerTwos. Step: 1080000. Time Elapsed: 2601.436 s. Mean Reward: 0.000. Mean Group Reward: 0.116. Training. ELO: 1320.505.\n",
      "[INFO] SoccerTwos. Step: 1090000. Time Elapsed: 2634.022 s. Mean Reward: 0.000. Mean Group Reward: 0.007. Training. ELO: 1320.172.\n",
      "[INFO] SoccerTwos. Step: 1100000. Time Elapsed: 2655.576 s. Mean Reward: 0.000. Mean Group Reward: -0.028. Training. ELO: 1318.263.\n",
      "[INFO] SoccerTwos. Step: 1110000. Time Elapsed: 2686.286 s. Mean Reward: 0.000. Mean Group Reward: 0.127. Training. ELO: 1320.150.\n",
      "[INFO] SoccerTwos. Step: 1120000. Time Elapsed: 2708.393 s. Mean Reward: 0.000. Mean Group Reward: 0.102. Training. ELO: 1320.758.\n",
      "[INFO] SoccerTwos. Step: 1130000. Time Elapsed: 2740.494 s. Mean Reward: 0.000. Mean Group Reward: 0.096. Training. ELO: 1317.465.\n",
      "[INFO] SoccerTwos. Step: 1140000. Time Elapsed: 2757.938 s. Mean Reward: 0.000. Mean Group Reward: 0.119. Training. ELO: 1324.695.\n",
      "[INFO] SoccerTwos. Step: 1150000. Time Elapsed: 2786.916 s. Mean Reward: 0.000. Mean Group Reward: 0.136. Training. ELO: 1329.060.\n",
      "[INFO] SoccerTwos. Step: 1160000. Time Elapsed: 2811.136 s. Mean Reward: 0.000. Mean Group Reward: 0.025. Training. ELO: 1328.960.\n",
      "[INFO] SoccerTwos. Step: 1170000. Time Elapsed: 2831.915 s. Mean Reward: 0.000. Mean Group Reward: 0.217. Training. ELO: 1333.182.\n",
      "[INFO] SoccerTwos. Step: 1180000. Time Elapsed: 2857.070 s. Mean Reward: 0.000. Mean Group Reward: 0.106. Training. ELO: 1333.726.\n",
      "[INFO] SoccerTwos. Step: 1190000. Time Elapsed: 2881.558 s. Mean Reward: 0.000. Mean Group Reward: 0.136. Training. ELO: 1333.326.\n",
      "[INFO] SoccerTwos. Step: 1200000. Time Elapsed: 2906.760 s. Mean Reward: 0.000. Mean Group Reward: 0.179. Training. ELO: 1330.887.\n",
      "[INFO] SoccerTwos. Step: 1210000. Time Elapsed: 2931.880 s. Mean Reward: 0.000. Mean Group Reward: 0.022. Training. ELO: 1330.996.\n",
      "[INFO] SoccerTwos. Step: 1220000. Time Elapsed: 2960.089 s. Mean Reward: 0.000. Mean Group Reward: 0.142. Training. ELO: 1330.865.\n",
      "[INFO] SoccerTwos. Step: 1230000. Time Elapsed: 2979.420 s. Mean Reward: 0.000. Mean Group Reward: 0.258. Training. ELO: 1338.041.\n",
      "[INFO] SoccerTwos. Step: 1240000. Time Elapsed: 3008.970 s. Mean Reward: 0.000. Mean Group Reward: 0.182. Training. ELO: 1341.976.\n",
      "[INFO] SoccerTwos. Step: 1250000. Time Elapsed: 3030.808 s. Mean Reward: 0.000. Mean Group Reward: 0.112. Training. ELO: 1345.697.\n",
      "[INFO] SoccerTwos. Step: 1260000. Time Elapsed: 3057.296 s. Mean Reward: 0.000. Mean Group Reward: 0.049. Training. ELO: 1344.345.\n",
      "[INFO] SoccerTwos. Step: 1270000. Time Elapsed: 3079.862 s. Mean Reward: 0.000. Mean Group Reward: 0.163. Training. ELO: 1340.949.\n",
      "[INFO] SoccerTwos. Step: 1280000. Time Elapsed: 3104.898 s. Mean Reward: 0.000. Mean Group Reward: -0.097. Training. ELO: 1339.996.\n",
      "[INFO] SoccerTwos. Step: 1290000. Time Elapsed: 3129.231 s. Mean Reward: 0.000. Mean Group Reward: 0.088. Training. ELO: 1343.251.\n",
      "[INFO] SoccerTwos. Step: 1300000. Time Elapsed: 3152.741 s. Mean Reward: 0.000. Mean Group Reward: 0.077. Training. ELO: 1346.155.\n",
      "[INFO] SoccerTwos. Step: 1310000. Time Elapsed: 3174.415 s. Mean Reward: 0.000. Mean Group Reward: 0.171. Training. ELO: 1350.949.\n",
      "[INFO] SoccerTwos. Step: 1320000. Time Elapsed: 3206.686 s. Mean Reward: 0.000. Mean Group Reward: 0.250. Training. ELO: 1362.524.\n",
      "[INFO] SoccerTwos. Step: 1330000. Time Elapsed: 3224.498 s. Mean Reward: 0.000. Mean Group Reward: 0.084. Training. ELO: 1362.877.\n",
      "[INFO] SoccerTwos. Step: 1340000. Time Elapsed: 3253.513 s. Mean Reward: 0.000. Mean Group Reward: 0.165. Training. ELO: 1369.292.\n",
      "[INFO] SoccerTwos. Step: 1350000. Time Elapsed: 3273.057 s. Mean Reward: 0.000. Mean Group Reward: 0.182. Training. ELO: 1373.893.\n",
      "[INFO] SoccerTwos. Step: 1360000. Time Elapsed: 3304.076 s. Mean Reward: 0.000. Mean Group Reward: 0.206. Training. ELO: 1379.191.\n",
      "[INFO] SoccerTwos. Step: 1370000. Time Elapsed: 3322.192 s. Mean Reward: 0.000. Mean Group Reward: -0.222. Training. ELO: 1379.860.\n",
      "[INFO] SoccerTwos. Step: 1380000. Time Elapsed: 3349.521 s. Mean Reward: 0.000. Mean Group Reward: -0.123. Training. ELO: 1372.971.\n",
      "[INFO] SoccerTwos. Step: 1390000. Time Elapsed: 3367.827 s. Mean Reward: 0.000. Mean Group Reward: -0.077. Training. ELO: 1370.498.\n",
      "[INFO] SoccerTwos. Step: 1400000. Time Elapsed: 3398.711 s. Mean Reward: 0.000. Mean Group Reward: 0.191. Training. ELO: 1374.945.\n",
      "[INFO] SoccerTwos. Step: 1410000. Time Elapsed: 3420.483 s. Mean Reward: 0.000. Mean Group Reward: 0.074. Training. ELO: 1377.249.\n",
      "[INFO] SoccerTwos. Step: 1420000. Time Elapsed: 3449.373 s. Mean Reward: 0.000. Mean Group Reward: 0.004. Training. ELO: 1379.408.\n",
      "[INFO] SoccerTwos. Step: 1430000. Time Elapsed: 3468.810 s. Mean Reward: 0.000. Mean Group Reward: -0.014. Training. ELO: 1377.500.\n",
      "[INFO] SoccerTwos. Step: 1440000. Time Elapsed: 3496.946 s. Mean Reward: 0.000. Mean Group Reward: 0.105. Training. ELO: 1378.587.\n",
      "[INFO] SoccerTwos. Step: 1450000. Time Elapsed: 3519.079 s. Mean Reward: 0.000. Mean Group Reward: 0.038. Training. ELO: 1383.461.\n",
      "[INFO] SoccerTwos. Step: 1460000. Time Elapsed: 3544.335 s. Mean Reward: 0.000. Mean Group Reward: 0.143. Training. ELO: 1382.466.\n",
      "[INFO] SoccerTwos. Step: 1470000. Time Elapsed: 3567.089 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training. ELO: 1385.701.\n",
      "[INFO] SoccerTwos. Step: 1480000. Time Elapsed: 3586.906 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training. ELO: 1389.867.\n",
      "[INFO] SoccerTwos. Step: 1490000. Time Elapsed: 3614.335 s. Mean Reward: 0.000. Mean Group Reward: -0.285. Training. ELO: 1380.962.\n",
      "[INFO] SoccerTwos. Step: 1500000. Time Elapsed: 3635.595 s. Mean Reward: 0.000. Mean Group Reward: 0.080. Training. ELO: 1375.768.\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-1499999.onnx\n",
      "[INFO] SoccerTwos. Step: 1510000. Time Elapsed: 3665.216 s. Mean Reward: 0.000. Mean Group Reward: -0.035. Training. ELO: 1382.783.\n",
      "[INFO] SoccerTwos. Step: 1520000. Time Elapsed: 3681.065 s. Mean Reward: 0.000. Mean Group Reward: 0.241. Training. ELO: 1385.138.\n",
      "[INFO] SoccerTwos. Step: 1530000. Time Elapsed: 3711.060 s. Mean Reward: 0.000. Mean Group Reward: 0.255. Training. ELO: 1393.408.\n",
      "[INFO] SoccerTwos. Step: 1540000. Time Elapsed: 3733.222 s. Mean Reward: 0.000. Mean Group Reward: 0.118. Training. ELO: 1399.044.\n",
      "[INFO] SoccerTwos. Step: 1550000. Time Elapsed: 3762.571 s. Mean Reward: 0.000. Mean Group Reward: 0.134. Training. ELO: 1400.403.\n",
      "[INFO] SoccerTwos. Step: 1560000. Time Elapsed: 3781.672 s. Mean Reward: 0.000. Mean Group Reward: 0.183. Training. ELO: 1407.306.\n",
      "[INFO] SoccerTwos. Step: 1570000. Time Elapsed: 3810.581 s. Mean Reward: 0.000. Mean Group Reward: 0.045. Training. ELO: 1415.330.\n",
      "[INFO] SoccerTwos. Step: 1580000. Time Elapsed: 3833.605 s. Mean Reward: 0.000. Mean Group Reward: 0.040. Training. ELO: 1421.143.\n",
      "[INFO] SoccerTwos. Step: 1590000. Time Elapsed: 3859.968 s. Mean Reward: 0.000. Mean Group Reward: 0.029. Training. ELO: 1417.447.\n",
      "[INFO] SoccerTwos. Step: 1600000. Time Elapsed: 3883.025 s. Mean Reward: 0.000. Mean Group Reward: 0.074. Training. ELO: 1419.364.\n",
      "[INFO] SoccerTwos. Step: 1610000. Time Elapsed: 3911.900 s. Mean Reward: 0.000. Mean Group Reward: -0.161. Training. ELO: 1416.779.\n",
      "[INFO] SoccerTwos. Step: 1620000. Time Elapsed: 3931.494 s. Mean Reward: 0.000. Mean Group Reward: -0.061. Training. ELO: 1413.700.\n",
      "[INFO] SoccerTwos. Step: 1630000. Time Elapsed: 3961.640 s. Mean Reward: 0.000. Mean Group Reward: 0.039. Training. ELO: 1410.281.\n",
      "[INFO] SoccerTwos. Step: 1640000. Time Elapsed: 3983.582 s. Mean Reward: 0.000. Mean Group Reward: 0.036. Training. ELO: 1412.219.\n",
      "[INFO] SoccerTwos. Step: 1650000. Time Elapsed: 4025.423 s. Mean Reward: 0.000. Mean Group Reward: 0.045. Training. ELO: 1413.047.\n",
      "[INFO] SoccerTwos. Step: 1660000. Time Elapsed: 4069.426 s. Mean Reward: 0.000. Mean Group Reward: 0.137. Training. ELO: 1410.083.\n",
      "[INFO] SoccerTwos. Step: 1670000. Time Elapsed: 4114.314 s. Mean Reward: 0.000. Mean Group Reward: 0.054. Training. ELO: 1411.713.\n",
      "[INFO] SoccerTwos. Step: 1680000. Time Elapsed: 4153.642 s. Mean Reward: 0.000. Mean Group Reward: -0.096. Training. ELO: 1411.505.\n",
      "[INFO] SoccerTwos. Step: 1690000. Time Elapsed: 4279.104 s. Mean Reward: 0.000. Mean Group Reward: -0.072. Training. ELO: 1407.142.\n",
      "[INFO] SoccerTwos. Step: 1700000. Time Elapsed: 4350.869 s. Mean Reward: 0.000. Mean Group Reward: 0.273. Training. ELO: 1407.892.\n",
      "[INFO] SoccerTwos. Step: 1710000. Time Elapsed: 4410.455 s. Mean Reward: 0.000. Mean Group Reward: 0.028. Training. ELO: 1412.250.\n",
      "[INFO] SoccerTwos. Step: 1720000. Time Elapsed: 4457.087 s. Mean Reward: 0.000. Mean Group Reward: -0.037. Training. ELO: 1415.639.\n",
      "[INFO] SoccerTwos. Step: 1730000. Time Elapsed: 4517.948 s. Mean Reward: 0.000. Mean Group Reward: -0.159. Training. ELO: 1417.413.\n",
      "[INFO] SoccerTwos. Step: 1740000. Time Elapsed: 4568.289 s. Mean Reward: 0.000. Mean Group Reward: 0.098. Training. ELO: 1415.730.\n",
      "[INFO] SoccerTwos. Step: 1750000. Time Elapsed: 4626.319 s. Mean Reward: 0.000. Mean Group Reward: 0.071. Training. ELO: 1414.937.\n",
      "[INFO] SoccerTwos. Step: 1760000. Time Elapsed: 4666.157 s. Mean Reward: 0.000. Mean Group Reward: -0.067. Training. ELO: 1414.308.\n",
      "[INFO] SoccerTwos. Step: 1770000. Time Elapsed: 4718.656 s. Mean Reward: 0.000. Mean Group Reward: -0.007. Training. ELO: 1410.445.\n",
      "[INFO] SoccerTwos. Step: 1780000. Time Elapsed: 4764.977 s. Mean Reward: 0.000. Mean Group Reward: -0.097. Training. ELO: 1410.612.\n",
      "[INFO] SoccerTwos. Step: 1790000. Time Elapsed: 4805.774 s. Mean Reward: 0.000. Mean Group Reward: -0.095. Training. ELO: 1408.199.\n",
      "[INFO] SoccerTwos. Step: 1800000. Time Elapsed: 4856.474 s. Mean Reward: 0.000. Mean Group Reward: -0.019. Training. ELO: 1408.776.\n",
      "[INFO] SoccerTwos. Step: 1810000. Time Elapsed: 4900.834 s. Mean Reward: 0.000. Mean Group Reward: 0.064. Training. ELO: 1411.922.\n",
      "[INFO] SoccerTwos. Step: 1820000. Time Elapsed: 4950.797 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training. ELO: 1419.812.\n",
      "[INFO] SoccerTwos. Step: 1830000. Time Elapsed: 4990.084 s. Mean Reward: 0.000. Mean Group Reward: -0.069. Training. ELO: 1422.168.\n",
      "[INFO] SoccerTwos. Step: 1840000. Time Elapsed: 5038.580 s. Mean Reward: 0.000. Mean Group Reward: -0.103. Training. ELO: 1423.243.\n",
      "[INFO] SoccerTwos. Step: 1850000. Time Elapsed: 5076.404 s. Mean Reward: 0.000. Mean Group Reward: -0.026. Training. ELO: 1420.717.\n",
      "[INFO] SoccerTwos. Step: 1860000. Time Elapsed: 5126.009 s. Mean Reward: 0.000. Mean Group Reward: -0.008. Training. ELO: 1417.839.\n",
      "[INFO] SoccerTwos. Step: 1870000. Time Elapsed: 5157.938 s. Mean Reward: 0.000. Mean Group Reward: 0.069. Training. ELO: 1419.416.\n",
      "[INFO] SoccerTwos. Step: 1880000. Time Elapsed: 5200.631 s. Mean Reward: 0.000. Mean Group Reward: -0.088. Training. ELO: 1421.859.\n",
      "[INFO] SoccerTwos. Step: 1890000. Time Elapsed: 5233.388 s. Mean Reward: 0.000. Mean Group Reward: -0.073. Training. ELO: 1422.312.\n",
      "[INFO] SoccerTwos. Step: 1900000. Time Elapsed: 5276.922 s. Mean Reward: 0.000. Mean Group Reward: -0.173. Training. ELO: 1423.787.\n",
      "[INFO] SoccerTwos. Step: 1910000. Time Elapsed: 5308.769 s. Mean Reward: 0.000. Mean Group Reward: 0.154. Training. ELO: 1423.816.\n",
      "[INFO] SoccerTwos. Step: 1920000. Time Elapsed: 5350.624 s. Mean Reward: 0.000. Mean Group Reward: -0.061. Training. ELO: 1424.627.\n",
      "[INFO] SoccerTwos. Step: 1930000. Time Elapsed: 5385.455 s. Mean Reward: 0.000. Mean Group Reward: 0.087. Training. ELO: 1425.675.\n",
      "[INFO] SoccerTwos. Step: 1940000. Time Elapsed: 5429.129 s. Mean Reward: 0.000. Mean Group Reward: 0.037. Training. ELO: 1423.949.\n",
      "[INFO] SoccerTwos. Step: 1950000. Time Elapsed: 5462.548 s. Mean Reward: 0.000. Mean Group Reward: -0.082. Training. ELO: 1425.562.\n",
      "[INFO] SoccerTwos. Step: 1960000. Time Elapsed: 5507.406 s. Mean Reward: 0.000. Mean Group Reward: 0.111. Training. ELO: 1427.207.\n",
      "[INFO] SoccerTwos. Step: 1970000. Time Elapsed: 5542.334 s. Mean Reward: 0.000. Mean Group Reward: 0.101. Training. ELO: 1430.899.\n",
      "[INFO] SoccerTwos. Step: 1980000. Time Elapsed: 5593.010 s. Mean Reward: 0.000. Mean Group Reward: -0.091. Training. ELO: 1430.501.\n",
      "[INFO] SoccerTwos. Step: 1990000. Time Elapsed: 5628.717 s. Mean Reward: 0.000. Mean Group Reward: 0.060. Training. ELO: 1430.544.\n",
      "[INFO] SoccerTwos. Step: 2000000. Time Elapsed: 5675.407 s. Mean Reward: 0.000. Mean Group Reward: -0.168. Training. ELO: 1432.717.\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-1999884.onnx\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-2000148.onnx\n",
      "[INFO] Copied results/SoccerTwos/SoccerTwos/SoccerTwos-2000148.onnx to results/SoccerTwos/SoccerTwos.onnx.\n"
     ]
    }
   ],
   "source": [
    "!mlagents-learn ./config/poca/SoccerTwos.yaml --env=./training-envs-executables/SoccerTwos.x86_64 --run-id=\"SoccerTwos\" --no-graphics --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72a7cc",
   "metadata": {},
   "source": [
    "# Интеграция с HuggingFace \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07252211",
   "metadata": {},
   "source": [
    "## Вход в аккаунт "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbe633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `hf auth whoami` to get more information or `hf auth logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): Traceback (most recent call last):\n",
      "  File \"/home/dmin/.local/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
      "    service.run()\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/commands/user.py\", line 113, in run\n",
      "    login(\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/_login.py\", line 130, in login\n",
      "    interpreter_login(new_session=new_session)\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dmin/.local/lib/python3.11/site-packages/huggingface_hub/_login.py\", line 287, in interpreter_login\n",
      "    token = getpass(\"Enter your token (input will not be visible): \")\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!hf auth login\n",
    "\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f1f1b",
   "metadata": {},
   "source": [
    "## Отправка решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd0dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] This function will create a model card and upload your SoccerTwos into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dmin/.local/bin/mlagents-push-to-hf\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dmin/HuggingFace/notebooks/unit7/ml-agents/ml-agents/mlagents/utils/push_to_hf.py\", line 205, in main\n",
      "    package_to_hub(\n",
      "  File \"/home/dmin/HuggingFace/notebooks/unit7/ml-agents/ml-agents/mlagents/utils/push_to_hf.py\", line 159, in package_to_hub\n",
      "    _generate_config(local_path, configfile_name)\n",
      "  File \"/home/dmin/HuggingFace/notebooks/unit7/ml-agents/ml-agents/mlagents/utils/push_to_hf.py\", line 29, in _generate_config\n",
      "    with open(os.path.join(local_dir, configfile_name)) as yaml_in:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'results/SoccerTwos/configuration.yaml'\n"
     ]
    }
   ],
   "source": [
    "!mlagents-push-to-hf  --run-id=\"SoccerTwos\" --local-dir=\"./results/SoccerTwos\" --repo-id=\"LizardAPN/poca-SoccerTwos\" --commit-message=\"feat: Initial commit of SoccerTwos model\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
